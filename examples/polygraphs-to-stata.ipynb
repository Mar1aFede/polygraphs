{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MON] step 0001 Ksteps/s   0.00 A/B 0.50/0.50\n",
      "[MON] step 0100 Ksteps/s   0.43 A/B 0.50/0.50\n",
      "[MON] step 0200 Ksteps/s   0.42 A/B 0.75/0.25\n",
      "[MON] step 0300 Ksteps/s   0.37 A/B 0.50/0.50\n",
      "[MON] step 0400 Ksteps/s   0.37 A/B 0.75/0.25\n",
      "[MON] step 0500 Ksteps/s   0.36 A/B 0.50/0.50\n",
      "[MON] step 0600 Ksteps/s   0.36 A/B 0.75/0.25\n",
      "[MON] step 0700 Ksteps/s   0.36 A/B 0.75/0.25\n",
      "[MON] step 0800 Ksteps/s   0.36 A/B 0.75/0.25\n",
      "[MON] step 0900 Ksteps/s   0.36 A/B 0.75/0.25\n",
      "[MON] step 1000 Ksteps/s   0.36 A/B 0.75/0.25\n",
      "[MON] step 1100 Ksteps/s   0.36 A/B 0.50/0.50\n",
      "[MON] step 1200 Ksteps/s   0.36 A/B 0.50/0.50\n",
      "[MON] step 1300 Ksteps/s   0.37 A/B 0.50/0.50\n",
      "[MON] step 1400 Ksteps/s   0.37 A/B 0.50/0.50\n",
      "[MON] step 1500 Ksteps/s   0.38 A/B 0.50/0.50\n",
      "[MON] step 1600 Ksteps/s   0.38 A/B 0.75/0.25\n",
      "[MON] step 1700 Ksteps/s   0.39 A/B 0.75/0.25\n",
      "[MON] step 1800 Ksteps/s   0.39 A/B 0.75/0.25\n",
      "[MON] step 1900 Ksteps/s   0.39 A/B 0.75/0.25\n",
      "[MON] step 2000 Ksteps/s   0.39 A/B 0.75/0.25\n",
      "[MON] step 2100 Ksteps/s   0.39 A/B 0.75/0.25\n",
      "[MON] step 2200 Ksteps/s   0.39 A/B 0.75/0.25\n",
      "[MON] step 2228 Ksteps/s   0.39 A/B 1.00/0.00\n",
      " INFO polygraphs> Sim #0001:   2228 steps    5.76s; action: A undefined: 0 converged: 1 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import dgl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import polygraphs as pg\n",
    "from polygraphs import graphs\n",
    "from polygraphs import hyperparameters as hparams\n",
    "from polygraphs import visualisations as viz\n",
    "from polygraphs import ops\n",
    "\n",
    "\n",
    "# Create a PolyGraph configuration\n",
    "params = hparams.PolyGraphHyperParameters()\n",
    "\n",
    "# Initial beliefs are random uniform between 0 and 1\n",
    "params.init.kind = 'uniform'\n",
    "# Chance that action B is better than action A\n",
    "params.epsilon = 0.001\n",
    "\n",
    "params.network.kind = 'complete'\n",
    "params.network.size = 4\n",
    "\n",
    "# Enable logging; print progress every 100 steps\n",
    "params.logging.enabled = True\n",
    "params.logging.interval = 100\n",
    "\n",
    "# Take snapshots\n",
    "params.snapshots.enabled = True\n",
    "params.snapshots.interval = 100\n",
    "\n",
    "params.simulation.steps = 0\n",
    "params.simulation.repeats = 1\n",
    "\n",
    "# Store results in directory\n",
    "params.simulation.results = \"data/test\"\n",
    "\n",
    "# Remove directory, if exists\n",
    "if os.path.isdir(params.simulation.results):\n",
    "    os.rmdir(params.simulation.results)\n",
    "\n",
    "# Set seed\n",
    "params.seed = 123456789\n",
    "\n",
    "pg.random(params.seed)\n",
    "_ = pg.simulate(params, op=ops.BalaGoyalOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBG> export to data/test/export-1.pj\n",
      "DBG> export to data/test/export-100.pj\n",
      "DBG> export to data/test/export-200.pj\n",
      "DBG> export to data/test/export-300.pj\n",
      "DBG> export to data/test/export-400.pj\n",
      "DBG> export to data/test/export-500.pj\n",
      "DBG> export to data/test/export-600.pj\n",
      "DBG> export to data/test/export-700.pj\n",
      "DBG> export to data/test/export-800.pj\n",
      "DBG> export to data/test/export-900.pj\n",
      "DBG> export to data/test/export-1000.pj\n",
      "DBG> export to data/test/export-1100.pj\n",
      "DBG> export to data/test/export-1200.pj\n",
      "DBG> export to data/test/export-1300.pj\n",
      "DBG> export to data/test/export-1400.pj\n",
      "DBG> export to data/test/export-1500.pj\n",
      "DBG> export to data/test/export-1600.pj\n",
      "DBG> export to data/test/export-1700.pj\n",
      "DBG> export to data/test/export-1800.pj\n",
      "DBG> export to data/test/export-1900.pj\n",
      "DBG> export to data/test/export-2000.pj\n",
      "DBG> export to data/test/export-2100.pj\n",
      "DBG> export to data/test/export-2200.pj\n",
      "DBG> export to data/test/export-2228.pj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Development/polygraphs/.venv/lib/python3.7/site-packages/networkx/readwrite/pajek.py:94: UserWarning: Edge attribute id is not processed. Non-string attribute.\n",
      "  f\"Edge attribute {k} is not processed. {('Empty attribute' if isinstance(v, str) else 'Non-string attribute')}.\"\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "def export(graph, path):\n",
    "    \"\"\"\n",
    "    Export graph to Pajek format.\n",
    "    \"\"\"\n",
    "    # Remove self-loops\n",
    "    g = dgl.remove_self_loop(graph)\n",
    "    graphx = nx.DiGraph(dgl.to_networkx(g))\n",
    "    nx.write_pajek(graphx, path)\n",
    "\n",
    "\n",
    "def postprocess(directory, id):\n",
    "    \"\"\"\n",
    "    Post-process graph snapshots\n",
    "    \"\"\"\n",
    "    # Resulting hashtable\n",
    "    ht = {}\n",
    "    graphs, _ = dgl.load_graphs(os.path.join(directory, f\"{id}.bin\"))\n",
    "    graph = graphs[0]\n",
    "    fp = h5py.File(os.path.join(directory, f\"{id}.hd5\"), \"r\")\n",
    "    _keys = [int(key) for key in fp.keys()]\n",
    "    _keys = sorted(_keys)\n",
    "    for key in _keys:\n",
    "        graph.ndata[\"beliefs\"] = torch.tensor(fp[str(key)][:])\n",
    "        dst = os.path.join(directory, f\"export-{key}.pj\")\n",
    "        print(f\"DBG> export to {dst}\")\n",
    "        export(graph, dst)\n",
    "\n",
    "\n",
    "ht = postprocess(\"data/test\", 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99d2daaa40f0c21b26b27a5491cef7acb4d77d22705671ecaa8729c6260e1a86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
