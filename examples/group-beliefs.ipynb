{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import dgl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import polygraphs as pg\n",
    "from polygraphs import graphs\n",
    "from polygraphs import hyperparameters as hparams\n",
    "from polygraphs import visualisations as viz\n",
    "from polygraphs import ops\n",
    "from polygraphs import init\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PolyGraph configuration\n",
    "params = hparams.PolyGraphHyperParameters()\n",
    "\n",
    "# Initial beliefs are random uniform between 0 and 1\n",
    "params.init.kind = 'uniform'\n",
    "# Chance that action B is better than action A\n",
    "params.epsilon = 0.001\n",
    "\n",
    "params.network.kind = 'barabasialbert'\n",
    "params.network.size = 128\n",
    "params.network.barabasialbert.attachments = 4\n",
    "\n",
    "# Enable logging; print progress every 100 steps\n",
    "params.logging.enabled = True\n",
    "params.logging.interval = 100\n",
    "\n",
    "# Take snapshots\n",
    "params.snapshots.enabled = True\n",
    "params.snapshots.interval = 100\n",
    "\n",
    "params.simulation.steps = 0\n",
    "params.simulation.repeats = 1\n",
    "\n",
    "# Store results in directory\n",
    "params.simulation.results = \"data/barabasialbert\"\n",
    "\n",
    "# Set seed\n",
    "params.seed = 123456789\n",
    "\n",
    "pg.random(params.seed)\n",
    "_ = pg.simulate(params, op=ops.BalaGoyalOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "# 1. Does a majority of nodes have a credence > 0.5?\n",
    "# 2. Does a supermajority of nodes have a credence > 0.5?\n",
    "\n",
    "# 3. Give each node its in degree number of votes, and let \n",
    "#    each node vote all its votes for B if its credence \n",
    "#    is > 0.5. Are a majority of votes for B?\n",
    "\n",
    "# 4. Give each node its out degree number of votes, and let each node vote all its votes for B if its credence is > 0. \n",
    "# Are a majority of votes for B?\n",
    "\n",
    "# 5. Take the average of the credences. Is this above 0.5?\n",
    "\n",
    "# 6. Take the average weighted by… the local clustering co-efficient? (That doesn’t seem right, as it basically measures density. Maybe the size of the [in or out] neighbourhood of the node divided by the size of the network?) Is this > 0.5?\n",
    "\n",
    "# 7. Geometric mean of credences (related to (5))?\n",
    "\n",
    "# 8. ...\n",
    "\n",
    "\n",
    "def sparsity(graph):\n",
    "    \"\"\"\n",
    "    Returns sparsity level of given DGL graph.\n",
    "    \"\"\"\n",
    "    # Remove self-loops\n",
    "    g = dgl.remove_self_loop(graph)\n",
    "    # Assumes an adjacency matrix of size N x N with M non-zero values\n",
    "    return g.num_edges() / (g.num_nodes() ** 2)\n",
    "\n",
    "\n",
    "def acc(graph):\n",
    "    \"\"\"\n",
    "    Returns average clustering coefficient.\n",
    "    \"\"\"\n",
    "    graphx = nx.DiGraph(dgl.to_networkx(graph))\n",
    "    return nx.algorithms.cluster.average_clustering(graphx)\n",
    "\n",
    "\n",
    "def apl(graph):\n",
    "    \"\"\"\n",
    "    Returns average shortest path length.\n",
    "    \"\"\"\n",
    "    graphx = nx.DiGraph(dgl.to_networkx(graph))\n",
    "    return nx.average_shortest_path_length(graphx)\n",
    "\n",
    "\n",
    "def majority(beliefs, threshold=0.5, weights=None):\n",
    "    \"\"\"\n",
    "    Returns percentage of nodes that believe B is better.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = torch.ones(beliefs.shape)\n",
    "\n",
    "    zeros = torch.zeros(beliefs.shape, dtype=weights.dtype)\n",
    "\n",
    "    # Count (normalized) votes\n",
    "    votes = torch.where(beliefs > threshold, weights, zeros)\n",
    "    result = votes.sum() / weights.sum()\n",
    "    return result.item()\n",
    "\n",
    "def average_credence(beliefs):\n",
    "    # print(\"Sum:\", beliefs.sum())\n",
    "    # print(\"# samples:\", len(beliefs))\n",
    "    return beliefs.sum() / len(beliefs)\n",
    "\n",
    "\n",
    "def filterfn(edges):\n",
    "    return torch.le(edges.src[\"beliefs\"], 0.5)\n",
    "   \n",
    "\n",
    "def postprocess(directory, id):\n",
    "    \"\"\"\n",
    "    Post-process graph snapshots\n",
    "    \"\"\"\n",
    "    # Resulting hashtable\n",
    "    ht = {}\n",
    "    graphs, _ = dgl.load_graphs(os.path.join(directory, f\"{id}.bin\"))\n",
    "    graph = graphs[0]\n",
    "    # Remove self-loops\n",
    "    graph = dgl.remove_self_loop(graph)\n",
    "    # Weights are the in-degrees\n",
    "    weights = graph.in_degrees()\n",
    "    # Weights are the out-degrees\n",
    "    # weights = graph.out_degrees()\n",
    "    # No weights\n",
    "    # weights = None\n",
    "    fp = h5py.File(os.path.join(directory, f\"{id}.hd5\"), \"r\")\n",
    "    _keys = [int(key) for key in fp.keys()]\n",
    "    _keys = sorted(_keys)\n",
    "    for key in _keys:\n",
    "        beliefs = torch.tensor(fp[str(key)][:])\n",
    "        ht[key] = majority(beliefs, threshold=0.7, weights=weights)\n",
    "    return ht\n",
    "\n",
    "\n",
    "ht = postprocess(\"data/complete\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'family':'sans-serif','sans-serif':['Arial'], 'size': 16})\n",
    "\n",
    "# Configure the y-axis - find max value and use discrete steps\n",
    "plt.ylim([0, 1])\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.ylabel('Majority')\n",
    "# Configure the x-axis\n",
    "plt.xlim([0, max(ht.keys())])\n",
    "plt.xlabel('Iterations')\n",
    "# Create a bar chart\n",
    "plt.plot(ht.keys(), \n",
    "         ht.values(),\n",
    "         '--o',\n",
    "         color='#B7BF35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99d2daaa40f0c21b26b27a5491cef7acb4d77d22705671ecaa8729c6260e1a86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
